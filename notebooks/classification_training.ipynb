{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CNNによる画像分類\n",
    "\n",
    "画像分類とは、画像の種類や状態を定量的に解析して特定のクラスに分類するタスクである。  \n",
    "ここでは、細胞画像を生細胞と死細胞に分類するタスクを学習するためのCNNを構築し、訓練および評価までの一連の作業を行う。\n",
    "\n",
    "## データセット\n",
    "\n",
    "`dataset_cls/` にHeLa細胞の位相差顕微鏡画像300枚 (生細胞150枚, 死細胞150枚) が格納されている。  \n",
    "画像サイズはすべて 128x128 pixel で、グレースケール画像となっている。  \n",
    "\n",
    "まず最初に画像を読み込み表示してみる。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import skimage.io as io\n",
    "\n",
    "%matplotlib inline\n",
    "img_live = io.imread('../datasets/dataset_cls/live/001.tif')\n",
    "io.imshow(img_live)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_dead = io.imread('../datasets/dataset_cls/dead/001.tif')\n",
    "io.imshow(img_dead)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 学習に用いるデータセットの準備\n",
    "\n",
    "データセットは、次の３つのカテゴリに分割する必要がある。\n",
    "\n",
    "* **train**: 訓練に用いるデータセット\n",
    "* **validation**: モデルの構造を決定するパラメータ (ハイパーパラメータ) を決めるために用いるデータセット\n",
    "* **test**: 検証に用いるデータセット\n",
    "\n",
    "それぞれどの画像がどのデータセットにカテゴライズされているか、`datasets/dataset_cls/split_list` にあるテキストファイル (`train.txt`, `validation.txt`, `test.txt`) にリストしてある。\n",
    "これらをカテゴライズしておく理由については、のちに説明する。\n",
    "\n",
    "また、画像分類の学習に用いるデータは、画像とラベル (今回は**死細胞のラベルを0**、**生細胞のラベルを1**とする)　をペアで用意する必要がある。\n",
    "\n",
    "あるカテゴリのデータセットから、画像とラベルをペアで用意するためのクラスを次のように作成する。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import skimage.io as io\n",
    "import chainer\n",
    "\n",
    "class PreprocessedDataset(chainer.dataset.DatasetMixin):\n",
    "    def __init__(\n",
    "            self,\n",
    "            root_path,\n",
    "            split_list\n",
    "    ):\n",
    "        self.root_path = root_path\n",
    "        with open(split_list) as f:\n",
    "            self.split_list = [line.rstrip() for line in f]\n",
    "        self.dtype = np.float32\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.split_list)\n",
    "\n",
    "    # 画像を返す\n",
    "    def _get_image(self, i):\n",
    "        image = io.imread(os.path.join(self.root_path, self.split_list[i]))\n",
    "        image = self._min_max_normalize_one_image(image)\n",
    "        return np.expand_dims(image.astype(self.dtype), axis=0)\n",
    "\n",
    "    # 画像を[0, 1]に正規化\n",
    "    def _min_max_normalize_one_image(self, image):\n",
    "        max_int = image.max()\n",
    "        min_int = image.min()\n",
    "        out = (image.astype(np.float32) - min_int) / (max_int - min_int)\n",
    "        return out\n",
    "    \n",
    "    # ラベル (生:1, 死: 0) を返す\n",
    "    def _get_label(self, i):\n",
    "        label = 0 if 'dead' in self.split_list[i] else 1\n",
    "        return label\n",
    "\n",
    "    # 画像とそれに紐づいたラベル (生:1, 死: 0) を返す\n",
    "    def get_example(self, i):\n",
    "        x, y = self._get_image(i), self._get_label(i)\n",
    "        return x, y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "このクラスでは、引数に渡した `split_list` (`train.txt`, `validation.txt`, `test.txt`のどれか) に従って、画像とラベルのペアを出力するための `get_example()` 関数が用意してある。  \n",
    "実際に、`get_example()` を次のように動かしてみる。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "root_path = '../datasets/dataset_cls'\n",
    "split_list = '../datasets/dataset_cls/split_list/train.txt'\n",
    "\n",
    "dataset = PreprocessedDataset(root_path, split_list)\n",
    "\n",
    "%matplotlib inline\n",
    "# train.txtの0番目の画像とラベルを取得\n",
    "img, label = dataset.get_example(0)\n",
    "plt.figure()\n",
    "plt.imshow(img[0], cmap='gray')\n",
    "plt.title('label: {}'.format(label))\n",
    "\n",
    "# train.txtの80番目の画像とラベルを取得\n",
    "img, label = dataset.get_example(80)\n",
    "plt.figure()\n",
    "plt.imshow(img[0], cmap='gray')\n",
    "plt.title('label: {}'.format(label))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "画像とラベルが正しい組み合わせで取得できていることが確認できた。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CNNモデルの定義\n",
    "\n",
    "画像分類を行うCNNは、畳み込み層と全結合層に分かれている。  \n",
    "畳み込み層は `L.Convolution2D(in_ch, out_ch, ksize, stride, pad)` ,\n",
    "全結合層は  `L.Linear(in_ch, out_ch)` のように記述する。  \n",
    "ここで指定する値は、モデルの構造を決定するパラメータ、すなわちハイパーパラメータと呼ばれる。\n",
    "\n",
    "```\n",
    "    in_ch:   入力チャネル数\n",
    "    out_ch:  出力チャネル数\n",
    "    ksize:   畳み込みカーネルサイズ\n",
    "    stride:  カーネルの移動サイズ\n",
    "    pad:     パディングサイズ\n",
    "```\n",
    "\n",
    "また、順伝搬されたデータを正規化するための層を正規化層と呼び、\n",
    "`L.BatchNormalization(in_ch)` のように記述する。\n",
    "\n",
    "参考: https://docs.chainer.org/en/stable/reference/links.html\n",
    "\n",
    "ここまで説明した層 (畳み込み層,  全結合層, 正規化層) はすべてパラメータを持っている。  \n",
    "一方で、パラメータを持たない、つまり学習によって更新はされない層や関数が存在する。\n",
    "\n",
    "CNNにおいてよく用いられる次元削減を行うための層としてプーリング層がある。\n",
    "プーリング層は `F.max_pooling_2d(input, ksize, stride)` のように記述する。\n",
    "また、代表的な活性化関数としてReLU (Rectified Linear Unit) があり、`F.relu(input)` と記述することができる。\n",
    "\n",
    "参考: https://docs.chainer.org/en/stable/reference/functions.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import chainer\n",
    "import chainer.functions as F\n",
    "import chainer.links as L\n",
    "\n",
    "class ClassificationModel(chainer.Chain):\n",
    "    def __init__(self, n_class=2):\n",
    "        super(ClassificationModel, self).__init__()\n",
    "        with self.init_scope():\n",
    "            # ネットワークの部品 (層) を用意\n",
    "            self.conv1 = L.Convolution2D(1, 32, 5, 1, 2)\n",
    "            self.bn1 = L.BatchNormalization(32)\n",
    "            self.conv2 = L.Convolution2D(32, 64, 5, 1, 2)\n",
    "            self.bn2 = L.BatchNormalization(64)\n",
    "            self.conv3 = L.Convolution2D(64, 128, 3, 1, 1)\n",
    "            self.bn3 = L.BatchNormalization(128)\n",
    "            self.conv4 = L.Convolution2D(128, 256, 3, 1, 1)\n",
    "            self.bn4 = L.BatchNormalization(256)\n",
    "            self.fc5 = L.Linear(16384, 1024)\n",
    "            self.fc6 = L.Linear(1024, n_class)\n",
    "            \n",
    "    def __call__(self, x):\n",
    "        # 各層を接続\n",
    "        h = F.relu(self.conv1(x))\n",
    "        h = F.max_pooling_2d(self.bn1(h), 2, 2)\n",
    "        h = F.relu(self.conv2(h))\n",
    "        h = F.max_pooling_2d(self.bn2(h), 2, 2)\n",
    "        h = F.relu(self.conv3(h))\n",
    "        h = F.max_pooling_2d(self.bn3(h), 2, 2)\n",
    "        h = F.relu(self.conv4(h))\n",
    "        h = F.max_pooling_2d(self.bn4(h), 2, 2)\n",
    "        h = F.dropout(F.relu(self.fc5(h)))\n",
    "        return self.fc6(h)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 出力関数\n",
    "\n",
    "ここまででCNNモデルに用いられる関数と伝搬の仕方を定義したが、最後の出力される層には別の関数を用いる。  \n",
    "この出力関数を用いることで、問題に応じた値の範囲になるように調節することができる。  \n",
    "一般的に、分類問題では出力関数に**Softmax**関数が用いられる。\n",
    "\n",
    "Softmax関数は、$d$次元のベクトル${\\bf y} \\in \\mathbb{R}^d$が与えられたとき、その各次元の値の合計が1になるように正規化することができる。\n",
    "すなわち、確率分布のような出力となる。\n",
    "${\\bf y}$の$i$番目の次元を$y_i$と書くと，Softmax関数は以下のように定義される。\n",
    "\n",
    "$$\n",
    "{\\rm Softmax}({\\bf y})_i = \\frac{\\exp(y_i)}{\\sum_{j=1}^d \\exp(y_j)}\n",
    "$$\n",
    "\n",
    "このように表現されるSoftmax関数を出力関数として用いる場合、`F.softmax` と記述する。\n",
    "\n",
    "参考: https://docs.chainer.org/en/stable/reference/generated/chainer.functions.softmax.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CNNモデルによる推論\n",
    "\n",
    "ここまでで、学習に用いるデータセットとCNNモデルを用意することができた。  \n",
    "まずはこれらを用いて、実際に画像分類の推論ができるのか試してみる。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import chainer.functions as F\n",
    "import chainer.links as L\n",
    "\n",
    "root_path = '../datasets/dataset_cls'\n",
    "split_list = '../datasets/dataset_cls/split_list/test.txt'\n",
    "\n",
    "# データセットを用意\n",
    "test_dataset = PreprocessedDataset(root_path, split_list)\n",
    "\n",
    "# 未学習のモデルを作成\n",
    "model = L.Classifier(ClassificationModel(n_class=2))\n",
    "\n",
    "print('=====================')\n",
    "for i in range(5):\n",
    "    with chainer.using_config('train', False):\n",
    "        # テスト画像とラベルを1セット取得\n",
    "        img, label = test_dataset.get_example(i)\n",
    "        # テスト画像の生死を推論\n",
    "        pred = model.predictor(np.expand_dims(img, axis=0))\n",
    "        # 出力関数により生・死の確率を求める\n",
    "        pred = F.softmax(pred)\n",
    "\n",
    "    print('test {}'.format(i + 1))\n",
    "    print('  pred: {}'.format(np.argmax(pred.data)))     # 確率が高い方のラベルを表示\n",
    "    print('  label: {}'.format(label))                                   # 正解のラベルを表示\n",
    "    print('=====================')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "このように、画像をCNNモデルに入力して、出力された結果から画像分類の推論を確認することができる。  \n",
    "ただ、このCNNモデルは学習が行われていない状態なので、画像分類の結果もランダムに出力した結果とさほど変わらないことがわかる。  \n",
    "では次に、すでに用意してある学習済みCNNモデルを使って推論を行なってみる。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import chainer.functions as F\n",
    "import chainer.links as L\n",
    "from chainer import serializers\n",
    "\n",
    "root_path = '../datasets/dataset_cls'\n",
    "split_list = '../datasets/dataset_cls/split_list/test.txt'\n",
    "model_path = '../models/inference_model'\n",
    "\n",
    "\n",
    "# データセットを用意\n",
    "test_dataset = PreprocessedDataset(root_path, split_list)\n",
    "\n",
    "# 未学習のモデルを作成\n",
    "model = L.Classifier(ClassificationModel(n_class=2))\n",
    "\n",
    "# 学習済みモデルの読み込み\n",
    "serializers.load_npz(model_path, model)\n",
    "\n",
    "\n",
    "print('=====================')\n",
    "for i in range(5):\n",
    "    with chainer.using_config('train', False):\n",
    "        # テスト画像とラベルを1セット取得\n",
    "        img, label = test_dataset.get_example(i)\n",
    "        # テスト画像の生死を推論\n",
    "        pred = model.predictor(np.expand_dims(img, axis=0))\n",
    "        # 出力関数により生・死の確率を求める\n",
    "        pred = F.softmax(pred)\n",
    "\n",
    "    print('test {}'.format(i + 1))\n",
    "    print('  pred: {}'.format(np.argmax(pred.data)))     # 確率が高い方のラベルを表示\n",
    "    print('  label: {}'.format(label))                                   # 正解のラベルを表示\n",
    "    print('=====================')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "学習済みモデルを用いた結果、推論結果と正解ラベルがすべて一致していることがわかる。  \n",
    "では次からは、学習を行うための準備を行なっていく。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 目的関数\n",
    "\n",
    "ここでは、上で定義したCNNモデルの目的関数 (誤差関数, 損失関数とも呼ばれる) を定義する。  \n",
    "目的関数はタスクごとに設定し、分類問題の場合は **Softmax Cross Entropy** 関数を用いるのが一般的である。  \n",
    "Softmax Cross Entropy関数は、Softmax関数とCross Entropy関数を組み合わせた関数である。\n",
    "\n",
    "Softmax関数は上述したため、ここではCross Entropy (交差エントロピー) 関数について説明する。\n",
    "$N$クラスの分類問題の場合、ある入力$x$が与えられたとき、ニューラルネットワークの出力層に$N$個のノードがあり、\n",
    "それぞれが$n$番目のクラスに属する確率$y_n$を表しているとする。\n",
    "ここで、$x$が所属するクラスについての正解が、${\\bf t} = \\begin{bmatrix} t_1 & t_2 & \\dots & t_N \\end{bmatrix}^T$というベクトルで与えられているとする。\n",
    "ただし、このベクトルは $t_n (n = 1, 2, \\dots, N)$ のいずれか1つだけが1であり、\n",
    "それ以外は0であるようなベクトル (1-hot ベクトル) であるとする。\n",
    "そして、この1つだけ値が1となっている要素は、その要素のインデックスに対応したクラスが正解であることを意味する。\n",
    "このとき、Cross Entropy関数は、以下のように定義される。\n",
    "\n",
    "$$\n",
    "{\\rm Cross\\ Entropy}({\\bf y}, {\\bf t}) = - \\frac{1}{N} \\sum_{n=1}^{N}t_{n}\\log({\\rm Softmax}({\\bf y})_{n})\n",
    "$$\n",
    "\n",
    "このように表現されるSoftmax Cross Entropy関数を目的関数として用いる場合、`F.softmax_cross_entropy` と記述する。\n",
    "\n",
    "参考: https://docs.chainer.org/en/stable/reference/generated/chainer.functions.softmax_cross_entropy.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CNNモデルの目的関数を定義\n",
    "\n",
    "ここでは、CNNモデルの出力から目的関数を用いて誤差 (loss) を計算するためのクラスを作成する。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import chainer\n",
    "import chainer.functions as F\n",
    "from chainer import reporter, Variable\n",
    "\n",
    "class Classifier(chainer.Chain):\n",
    "    def __init__(self, predictor):\n",
    "        super(Classifier, self).__init__()\n",
    "        with self.init_scope():\n",
    "            self.predictor = predictor\n",
    "\n",
    "    def __call__(self, x, t):\n",
    "        y = self.predictor(x)\n",
    "        # 目的関数を設定\n",
    "        loss = F.softmax_cross_entropy(y, t)\n",
    "        # 誤差を記録\n",
    "        reporter.report({'loss': loss}, self)\n",
    "        return loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 最適化手法\n",
    "\n",
    "ニューラルネットワークにおける学習は、上述した目的関数を最小化するために最適化を行う必要がある。\n",
    "この最適化手法は勾配法がベースとなっており、学習時に用いる最適化手法はこれまでに数多く提案されている (参考: https://qiita.com/tokkuman/items/1944c00415d129ca0ee9 )。\n",
    "\n",
    "Chainerにも多くの最適化手法が実装されているが、今回はその中でも最も用いられている**Adam**という最適化手法を採用する。  \n",
    "Adamを用いる場合には、`optimizers.Adam` と記述する。\n",
    "\n",
    "参考: https://docs.chainer.org/en/stable/reference/optimizers.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CNNモデルの学習\n",
    "\n",
    "CNNモデルに目的関数を定義して、最適化手法も決定したため、実際に学習を行なってみる。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import chainer\n",
    "from chainer import cuda\n",
    "import chainer.functions as F\n",
    "from chainer import optimizers, iterators, training\n",
    "\n",
    "def create_trainer(root_path, train_path, val_path, batchsize, epoch, out='result_cls', device=-1):\n",
    "\n",
    "    # train データセットを用意\n",
    "    train_dataset = PreprocessedDataset(root_path, train_path)\n",
    "    # validation データセットを用意\n",
    "    val_dataset = PreprocessedDataset(root_path, val_path)\n",
    "    \n",
    "    # 未学習のモデルを作成\n",
    "    model = ClassificationModel(n_class=2)\n",
    "    train_model = Classifier(model)\n",
    "\n",
    "    # 最適化手法を選択 (Adam)\n",
    "    optimizer = optimizers.Adam()\n",
    "    optimizer.setup(train_model)\n",
    "\n",
    "    # train データセットを学習器に渡す形式に変換\n",
    "    train_iter = iterators.MultiprocessIterator(train_dataset, batchsize)\n",
    "    # validation データセットを学習器に渡す形式に変換\n",
    "    val_iter = iterators.MultiprocessIterator(val_dataset, batchsize, repeat=False, shuffle=False)\n",
    "\n",
    "    # 誤差から学習器の重みを更新するアップデーターを作成\n",
    "    updater = training.StandardUpdater(train_iter, optimizer, device=device)\n",
    "\n",
    "    # 今回実行したいタスクを設定\n",
    "    trainer = training.trainer.Trainer(updater, epoch, out=out)\n",
    "\n",
    "    # 学習中に何を記録するかを設定 (エポック, 訓練誤差, 検証誤差, 実行時間)\n",
    "    logging_attributes = ['epoch', 'main/loss', 'val/main/loss', 'elapsed_time']\n",
    "    # 上記 logging_attributes をログとして記録\n",
    "    trainer.extend(training.extensions.LogReport(logging_attributes))\n",
    "    # 上記 logging_attributes を画面に表示   \n",
    "    trainer.extend(training.extensions.PrintReport(logging_attributes))\n",
    "    # 訓練誤差と検証誤差をプロット   \n",
    "    trainer.extend(training.extensions.PlotReport(['main/loss', 'val/main/loss'], 'epoch', file_name='loss.png'))\n",
    "    # 検証用データの評価の設定\n",
    "    trainer.extend(training.extensions.Evaluator(val_iter, train_model, device=device), name='val')\n",
    "    # 検証誤差が最小時のモデルを保存\n",
    "    trainer.extend(training.extensions.snapshot_object(train_model, filename='best_loss_model'), trigger=training.triggers.MinValueTrigger('val/main/loss', trigger=(1, 'epoch')))\n",
    "    return trainer\n",
    "\n",
    "\n",
    "os.makedirs('results', exist_ok=True)\n",
    "root_path = '../datasets/dataset_cls'\n",
    "train_path = '../datasets/dataset_cls/split_list/train.txt'\n",
    "val_path = '../datasets/dataset_cls/split_list/validation.txt'\n",
    "batchsize = 2\n",
    "epoch = (10, 'epoch')\n",
    "\n",
    "trainer = create_trainer(root_path, train_path, val_path, batchsize, epoch, out='results/result_cls_1', device=-1)\n",
    "\n",
    "# 訓練開始\n",
    "trainer.run()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "学習が進むにつれて訓練データの誤差 (`main/loss`) が低下していることがわかる。\n",
    "つまり、学習が正常に進んでいることがわかる。\n",
    "このように、lossを継時的に観察することで、学習の進行度を確認することができる。\n",
    "また、検証データの誤差 (`val/main/loss`) がもっとも低いとき、学習が収束したと判定することができる。\n",
    "一方で、学習の評価指標が誤差のみだと、実際に画像分類がうまく行われているのか確認することができない。\n",
    "そこで、学習時に観察する指標を新たに導入することを考える。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 画像分類精度の評価指標\n",
    "\n",
    "一般的に、分類問題の精度は**Accuracy**という指標で評価される。Accuracyは全画像のうち何枚の画像を正しく分類できたかを割合で表される指標である。すなわち、Accuracyが高いほど分類精度も高いということになる。 \n",
    "正解クラスが$i$である画像をCNNモデルがクラス$j$に分類した数を$N_{ij}$とすると、クラス数が$k$のとき、Accuracyは以下のようになる。\n",
    "\n",
    "$$\n",
    "{\\rm Accuracy} = \\frac{\\sum_{i=1}^k N_{ii}}{\\sum_{i=1}^k \\sum_{j=1}^k N_{ij}}\n",
    "$$\n",
    "\n",
    "Accuracyを用いる場合、`F.accuracy` と記述する。\n",
    "\n",
    "参考: https://docs.chainer.org/en/stable/reference/generated/chainer.functions.accuracy.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import chainer\n",
    "import chainer.functions as F\n",
    "from chainer import reporter, Variable\n",
    "\n",
    "class Classifier(chainer.Chain):\n",
    "    def __init__(self, predictor):\n",
    "        super(Classifier, self).__init__()\n",
    "        with self.init_scope():\n",
    "            self.predictor = predictor\n",
    "\n",
    "    def __call__(self, x, t):\n",
    "        y = self.predictor(x)\n",
    "        # 目的関数を設定\n",
    "        loss = F.softmax_cross_entropy(y, t)\n",
    "        with chainer.no_backprop_mode():\n",
    "            # 分類精度を計算\n",
    "            accuracy = F.accuracy(y, t)\n",
    "        # 誤差, 分類精度を記録\n",
    "        reporter.report({'loss': loss, 'accuracy': accuracy}, self)\n",
    "        return loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Accuracyを指標とした学習\n",
    "\n",
    "先ほどまではlossのみで学習の進行度と収束判定を行なっていたが、今度は導入したAccuracyを用いて同様に学習してみる。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import chainer\n",
    "from chainer import cuda\n",
    "import chainer.functions as F\n",
    "from chainer import optimizers, iterators, training\n",
    "\n",
    "def create_trainer(root_path, train_path, val_path, batchsize, epoch, out='result_cls', device=-1):\n",
    "\n",
    "    train_dataset = PreprocessedDataset(root_path, train_path)\n",
    "    val_dataset = PreprocessedDataset(root_path, val_path)\n",
    "    \n",
    "    model = ClassificationModel(n_class=2)\n",
    "    train_model = Classifier(model)\n",
    "\n",
    "    optimizer = optimizers.Adam()\n",
    "    optimizer.setup(train_model)\n",
    "\n",
    "    train_iter = iterators.MultiprocessIterator(train_dataset, batchsize)\n",
    "    val_iter = iterators.MultiprocessIterator(val_dataset, batchsize, repeat=False, shuffle=False)\n",
    "\n",
    "    updater = training.StandardUpdater(train_iter, optimizer, device=device)\n",
    "\n",
    "    trainer = training.trainer.Trainer(updater, epoch, out=out)\n",
    "\n",
    "    # 学習中に分類精度 (accuracy) も記録するように設定\n",
    "    logging_attributes = ['epoch', 'main/loss', 'main/accuracy', 'val/main/loss', 'val/main/accuracy', 'elapsed_time']\n",
    "    trainer.extend(training.extensions.LogReport(logging_attributes))\n",
    "    trainer.extend(training.extensions.PrintReport(logging_attributes))\n",
    "    trainer.extend(training.extensions.PlotReport(['main/loss', 'val/main/loss'], 'epoch', file_name='loss.png'))\n",
    "    # 訓練精度と検証精度をプロット \n",
    "    trainer.extend(training.extensions.PlotReport(['main/accuracy', 'val/main/accuracy'], 'epoch', file_name='accuracy.png'))\n",
    "    trainer.extend(training.extensions.Evaluator(val_iter, train_model, device=device), name='val')\n",
    "    # 検証精度が最高時のモデルを保存\n",
    "    trainer.extend(training.extensions.snapshot_object(train_model, filename='best_acc_model'), trigger=training.triggers.MaxValueTrigger('val/main/accuracy', trigger=(1, 'epoch')))\n",
    "    return trainer\n",
    "\n",
    "\n",
    "root_path = '../datasets/dataset_cls'\n",
    "train_path = '../datasets/dataset_cls/split_list/train.txt'\n",
    "val_path = '../datasets/dataset_cls/split_list/test.txt'\n",
    "batchsize = 2\n",
    "epoch = (10, 'epoch')\n",
    "\n",
    "trainer = create_trainer(root_path, train_path, val_path, batchsize, epoch, out='results/result_cls_2', device=-1)\n",
    "trainer.run()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## テストデータを用いた画像分類の精度"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import chainer\n",
    "from chainer import cuda\n",
    "import chainer.functions as F\n",
    "from chainer import serializers\n",
    "\n",
    "def test(root_path, test_path, model_path, out='results/result_cls_test', device=-1):\n",
    "\n",
    "    # データセットを用意\n",
    "    test_dataset = PreprocessedDataset(root_path, test_path)\n",
    "    \n",
    "    # 未学習のモデルを作成\n",
    "    model = ClassificationModel(n_class=2)\n",
    "    train_model = Classifier(model)\n",
    "    \n",
    "    # 学習済みモデルの読み込み\n",
    "    serializers.load_npz(model_path, train_model)\n",
    "    \n",
    "    true_conut = 0\n",
    "    for i in range(test_dataset.__len__()):\n",
    "        with chainer.using_config('train', False):\n",
    "            # テスト画像とラベルを1セット取得\n",
    "            x, t = test_dataset.get_example(i)\n",
    "            # テスト画像の生死を推論\n",
    "            y = train_model.predictor(np.expand_dims(x, axis=0))\n",
    "        # 推論した分類結果が正解ラベルと一致していたら true_count　に1を加算\n",
    "        if np.argmax(y.data) == t:\n",
    "            true_conut += 1\n",
    "    # accuracy を算出\n",
    "    accuracy = true_conut / test_dataset.__len__()\n",
    "    os.makedirs(out, exist_ok=True)\n",
    "    with open(os.path.join(out, 'result.txt'), 'w') as f:\n",
    "        f.write('accuracy: {}\\n'.format(accuracy))\n",
    "    print('accuracy: {}'.format(accuracy))\n",
    "    \n",
    "    \n",
    "root_path = '../datasets/dataset_cls'\n",
    "test_path = '../datasets/dataset_cls/split_list/test.txt'\n",
    "\n",
    "# 検証誤差が最小の学習済みモデルでテスト\n",
    "model_path = 'results/result_cls_1/best_loss_model'\n",
    "test(root_path, test_path, model_path, 'results/result_cls_1_test', device=-1)\n",
    "\n",
    "# 検証精度が最高の学習済みモデルでテスト\n",
    "model_path = 'results/result_cls_2/best_acc_model'\n",
    "test(root_path, test_path, model_path, 'results/result_cls_2_test', device=-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5分割交差検証 (5-fold cross validation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "交差検証 (cross validation) とは、学習の妥当性を検証・確認するための手法である。\n",
    "K-分割交差検証 (K-fold cross validation) では、データセットをK個に分割する。\n",
    "次に、分割した1つのデータセットを検証データとし、残る  K - 1個を訓練データとする。\n",
    "交差検証は、K 個に分割されたデータセットをそれぞれ検証データとして K 回検証を行う。\n",
    "このようにして得られた K 回の結果を平均することで、データセット全体に対してうまく学習できているか評価を行うことができる。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "root_path = '../datasets/dataset_cls'\n",
    "batchsize = 2\n",
    "epoch = (10, 'epoch')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## fold 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_path_fold1 = '../datasets/dataset_cls/split_list/fold1/train.txt'\n",
    "val_path_fold1 = '../datasets/dataset_cls/split_list/fold1/validation.txt'\n",
    "\n",
    "trainer_fold1 = create_trainer(root_path, train_path_fold1, val_path_fold1, batchsize, epoch=epoch, out='results/result_cls_fold1', device=-1)\n",
    "trainer_fold1.run()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## fold 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_path_fold2 = '../datasets/dataset_cls/split_list/fold2/train.txt'\n",
    "val_path_fold2 = '../datasets/dataset_cls/split_list/fold2/validation.txt'\n",
    "\n",
    "trainer_fold2 = create_trainer(root_path, train_path_fold2, val_path_fold2, batchsize, epoch=epoch, out='results/result_cls_fold2', device=-1)\n",
    "trainer_fold2.run()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## fold 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_path_fold3 = '../datasets/dataset_cls/split_list/fold3/train.txt'\n",
    "val_path_fold3 = '../datasets/dataset_cls/split_list/fold3/validation.txt'\n",
    "\n",
    "trainer_fold3 = create_trainer(root_path, train_path_fold3, val_path_fold3, batchsize, epoch=epoch, out='results/result_cls_fold3', device=-1)\n",
    "trainer_fold3.run()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## fold 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_path_fold4 = '../datasets/dataset_cls/split_list/fold4/train.txt'\n",
    "val_path_fold4 = '../datasets/dataset_cls/split_list/fold4/validation.txt'\n",
    "\n",
    "trainer_fold4 = create_trainer(root_path, train_path_fold4, val_path_fold4, batchsize, epoch=epoch, out='results/result_cls_fold4', device=-1)\n",
    "trainer_fold4.run()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## fold 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_path_fold5 = '../datasets/dataset_cls/split_list/fold5/train.txt'\n",
    "val_path_fold5 = '../datasets/dataset_cls/split_list/fold5/validation.txt'\n",
    "\n",
    "trainer_fold5 = create_trainer(root_path, train_path_fold5, val_path_fold5, batchsize, epoch=epoch, out='results/result_cls_fold5', device=-1)\n",
    "trainer_fold5.run()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cross Validationの評価"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import json\n",
    "import matplotlib.pylab as plt\n",
    "\n",
    "res_cv_path = glob.glob('results/result_cls_fold*')\n",
    "res_log = []\n",
    "for cv in res_cv_path:\n",
    "    with open(os.path.join(cv, 'log'), 'r') as f:\n",
    "        res_log.append(json.load(f))\n",
    "\n",
    "\n",
    "%matplotlib inline\n",
    "    \n",
    "plt.figure(figsize=(18, 10))\n",
    "for k in range(len(res_log)):\n",
    "    train, val, epoch = [], [], []\n",
    "    for n in range(len(res_log[k])):\n",
    "        train.append(res_log[k][n]['main/accuracy'])\n",
    "        val.append(res_log[k][n]['val/main/accuracy'])\n",
    "        epoch.append(res_log[k][n]['epoch'])\n",
    "    plt.subplot(2, 3, k+1)\n",
    "    plt.plot(epoch, train, label='Train', color='blue')\n",
    "    plt.plot(epoch, val, label='Validation', color='orange')\n",
    "    plt.scatter(np.argmax(val)+1, np.max(val), marker='o', color='orange')\n",
    "    plt.xticks(epoch)\n",
    "    plt.xlabel('epoch')\n",
    "    plt.ylabel('accuracy')\n",
    "    plt.title('fold{}: max accuracy={}'.format(k+1, np.max(val)))\n",
    "    plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# テストデータによる検証\n",
    "\n",
    "ここまでで train, validation　データを用いて学習を行ったので、学習に関与させていない test データを用いて得られた学習済みモデルの精度を検証する。\n",
    "一般的には、交差検証においてもっとも優れた精度を示したモデルを用いて検証を行う。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## テスト関数の作成"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import chainer\n",
    "from chainer import cuda\n",
    "import chainer.functions as F\n",
    "from chainer import serializers\n",
    "\n",
    "def test(root_path, test_path, model_path, out='results/result_cls_test', device=-1):\n",
    "    test_dataset = PreprocessedDataset(root_path, test_path)\n",
    "    \n",
    "    model = ClassificationModel(n_class=2)\n",
    "    train_model = Classifier(model)\n",
    "    serializers.load_npz(model_path, train_model)\n",
    "    \n",
    "    tp, tn, fp, fn = 0, 0, 0, 0\n",
    "    for i in range(test_dataset.__len__()):\n",
    "        with chainer.using_config('train', False):\n",
    "            x, t = test_dataset.get_example(i)\n",
    "            y = train_model.predictor(np.expand_dims(x, axis=0))\n",
    "        if np.argmax(y.data) == t:\n",
    "            if t == 1:\n",
    "                tp += 1\n",
    "            else:\n",
    "                tn += 1\n",
    "        else:\n",
    "            if t == 1:\n",
    "                fn += 1\n",
    "            else:\n",
    "                fp += 1\n",
    "            \n",
    "    accuracy = (tp + tn) / (tp + tn + fp + fn)\n",
    "    precision = tp / (tp + fp)\n",
    "    recall = tp / (tp + fn)\n",
    "    fscore = 2 * precision * recall / (precision + recall)\n",
    "    \n",
    "    os.makedirs(out, exist_ok=True)\n",
    "    with open(os.path.join(out, 'result.txt'), 'w') as f:\n",
    "        f.write('accuracy: {}\\n'.format(accuracy))\n",
    "        f.write('precision: {}\\n'.format(precision))\n",
    "        f.write('recall: {}\\n'.format(recall))\n",
    "        f.write('f-score: {}\\n'.format(fscore))\n",
    "    print('accuracy: {}'.format(accuracy))\n",
    "    print('precision: {}'.format(precision))\n",
    "    print('recall: {}'.format(recall))\n",
    "    print('f-score: {}'.format(fscore))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## テスト"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "root_path = '../datasets/dataset_cls'\n",
    "test_path = '../datasets/dataset_cls/split_list/test.txt'\n",
    "model_path = 'results/result_cls_fold2/best_acc_model'\n",
    "\n",
    "test(root_path, test_path, model_path, 'results/result_cls_test', device=-1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
